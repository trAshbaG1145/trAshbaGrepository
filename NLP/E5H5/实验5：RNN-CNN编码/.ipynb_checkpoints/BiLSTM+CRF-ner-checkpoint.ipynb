{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9e9f36c4-ff2d-4976-a109-c65e74787f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from TorchCRF import CRF\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e4c2e75-80fe-4e68-a52f-f171e83b8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "sentences = [\n",
    "    [\"I\", \"live\", \"in\", \"New\", \"York\", \".\"],\n",
    "    [\"Barack\", \"Obama\", \"was\", \"the\", \"president\", \"of\", \"the\", \"United\", \"States\", \".\"],\n",
    "    [\"Apple\", \"is\", \"looking\", \"at\", \"buying\", \"U.K.\", \"startup\", \"for\", \"around\", \"$\", \"1\", \"billion\", \".\"],\n",
    "    [\"London\", \"is\", \"the\", \"capital\", \"of\", \"England\", \".\"],\n",
    "]\n",
    "labels = [\n",
    "    [\"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\"],\n",
    "    [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"I-LOC\", \"O\"],\n",
    "    [\"B-ORG\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"],\n",
    "    [\"B-LOC\", \"O\", \"O\", \"O\", \"B-LOC\", \"I-LOC\", \"O\"],\n",
    "]\n",
    "\n",
    "# 词汇表和标签编码\n",
    "word_list = list(set(word for sentence in sentences for word in sentence))\n",
    "tag_list = list(set(tag for label in labels for tag in label))\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(word_list)}\n",
    "tag_to_ix = {tag: i for i, tag in enumerate(tag_list)}\n",
    "ix_to_tag = {i: tag for tag, i in tag_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3dbc5b68-f814-40fb-8832-f1382a73aee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I-PER',\n",
       " 1: 'B-ORG',\n",
       " 2: 'I-ORG',\n",
       " 3: 'B-LOC',\n",
       " 4: 'B-PER',\n",
       " 5: 'I-LOC',\n",
       " 6: 'O'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf85f0f2-5996-405d-a51e-17763ec34f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-PER': 0,\n",
       " 'B-ORG': 1,\n",
       " 'I-ORG': 2,\n",
       " 'B-LOC': 3,\n",
       " 'B-PER': 4,\n",
       " 'I-LOC': 5,\n",
       " 'O': 6}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1c2e5c44-aa55-44b8-bc8c-d284f84b38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'was': 0,\n",
       " 'I': 1,\n",
       " '1': 2,\n",
       " 'the': 3,\n",
       " 'Obama': 4,\n",
       " 'New': 5,\n",
       " '.': 6,\n",
       " '$': 7,\n",
       " 'capital': 8,\n",
       " 'U.K.': 9,\n",
       " 'in': 10,\n",
       " 'Apple': 11,\n",
       " 'York': 12,\n",
       " 'Barack': 13,\n",
       " 'president': 14,\n",
       " 'is': 15,\n",
       " 'at': 16,\n",
       " 'billion': 17,\n",
       " 'London': 18,\n",
       " 'startup': 19,\n",
       " 'buying': 20,\n",
       " 'of': 21,\n",
       " 'England': 22,\n",
       " 'around': 23,\n",
       " 'for': 24,\n",
       " 'United': 25,\n",
       " 'live': 26,\n",
       " 'looking': 27,\n",
       " 'States': 28}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "241dea1e-bf59-47cc-be9b-a3da5eaf8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备，添加填充\n",
    "def prepare_data(sentences, labels):\n",
    "    max_len = max(len(sentence) for sentence in sentences)  # 找到最长的句子长度\n",
    "    X = [[word_to_ix[word] for word in sentence] + [0] * (max_len - len(sentence)) for sentence in sentences]  # 使用0填充\n",
    "    y = [[tag_to_ix[tag] for tag in label] + [tag_to_ix[\"O\"]] * (max_len - len(label)) for label in labels]  # 使用O填充\n",
    "    mask = [[1] * len(label) + [0] * (max_len - len(label)) for label in labels]  # 生成mask\n",
    "    return X, y, mask\n",
    "\n",
    "X, y, mask = prepare_data(sentences, labels)\n",
    "X = torch.tensor(X, dtype=torch.long)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "mask = torch.tensor(mask, dtype=torch.bool)  # 转换为布尔类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a7ac3aa-b3cd-4921-987b-e09a49157b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 26, 10,  5, 12,  6,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [13,  4,  0,  3, 14, 21,  3, 25, 28,  6,  0,  0,  0],\n",
       "        [11, 15, 27, 16, 20,  9, 19, 24, 23,  7,  2, 17,  6],\n",
       "        [18, 15,  3,  8, 21, 22,  6,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05644885-a8b3-465e-8f3b-48ae6fafabcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6, 6, 3, 5, 6, 6, 6, 6, 6, 6, 6, 6],\n",
       "        [4, 0, 6, 6, 6, 6, 3, 5, 5, 6, 6, 6, 6],\n",
       "        [1, 6, 6, 6, 1, 2, 6, 6, 6, 6, 6, 6, 6],\n",
       "        [3, 6, 6, 6, 3, 5, 6, 6, 6, 6, 6, 6, 6]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d13a106a-cac4-4205-8f10-994cc95fc25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "EMBEDDING_DIM =64\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "# BiLSTM + CRF 模型\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tag_size, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc = nn.Linear(hidden_dim, tag_size)\n",
    "        self.crf = CRF(tag_size)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        embeddings = self.embedding(sentences)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        emissions = self.fc(lstm_out)\n",
    "        return emissions\n",
    "\n",
    "    def loss(self, sentences, tags, mask):\n",
    "        emissions = self.forward(sentences)\n",
    "        # 计算损失\n",
    "        return self.crf(emissions, tags, mask=mask)\n",
    "\n",
    "    def predict(self, sentences, mask):\n",
    "        with torch.no_grad():\n",
    "            emissions = self.forward(sentences)\n",
    "            # 计算最优路径\n",
    "            return self.crf.viterbi_decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c81a4fc3-d305-4ba4-8957-7be343afd225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -18.066131591796875\n",
      "Epoch 2, Loss: -18.38288116455078\n",
      "Epoch 3, Loss: -18.702377319335938\n",
      "Epoch 4, Loss: -19.02557373046875\n",
      "Epoch 5, Loss: -19.353496551513672\n",
      "Epoch 6, Loss: -19.687332153320312\n",
      "Epoch 7, Loss: -20.02839469909668\n",
      "Epoch 8, Loss: -20.37810516357422\n",
      "Epoch 9, Loss: -20.737934112548828\n",
      "Epoch 10, Loss: -21.109386444091797\n",
      "Epoch 11, Loss: -21.49394989013672\n",
      "Epoch 12, Loss: -21.89310073852539\n",
      "Epoch 13, Loss: -22.30831527709961\n",
      "Epoch 14, Loss: -22.741079330444336\n",
      "Epoch 15, Loss: -23.19290542602539\n",
      "Epoch 16, Loss: -23.665363311767578\n",
      "Epoch 17, Loss: -24.16005516052246\n",
      "Epoch 18, Loss: -24.678665161132812\n",
      "Epoch 19, Loss: -25.222936630249023\n",
      "Epoch 20, Loss: -25.79469108581543\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "model = BiLSTM_CRF(len(word_list), len(tag_list), EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.loss(X, y, mask)\n",
    "    loss_value = loss.mean()  # 确保损失是标量\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss_value.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b60dffc-6715-4f37-8210-8bea0537837d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'B-ORG'), ('was', 'I-LOC'), ('in', 'B-ORG'), ('in', 'I-LOC'), ('in', 'B-ORG'), ('London', 'B-ORG'), ('.', 'I-LOC')]\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "model.eval()\n",
    "test_sentence = [\"I\", \"was\",\"in\",\"in\", \"in\", \"London\", \".\"]\n",
    "max_len = max(len(sentence) for sentence in sentences)  # 重用 max_len\n",
    "test_tensor = torch.tensor([[word_to_ix[word] for word in test_sentence] + [0] * (max_len - len(test_sentence))], dtype=torch.long)\n",
    "test_mask = torch.tensor([[1] * len(test_sentence) + [0] * (max_len - len(test_sentence))], dtype=torch.bool)  # 转换为布尔类型\n",
    "predicted_tags = model.predict(test_tensor, test_mask)\n",
    "\n",
    "# 显示预测结果\n",
    "predicted_labels = [ix_to_tag[tag] for tag in predicted_tags[0]]  # 获取第一个预测序列\n",
    "print(list(zip(test_sentence, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41527c4d-d3ff-446d-97a0-36c9d1f7512d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
