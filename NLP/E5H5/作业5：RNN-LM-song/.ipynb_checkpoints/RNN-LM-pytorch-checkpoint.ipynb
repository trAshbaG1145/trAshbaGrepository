{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4726decb-8807-4777-80aa-475c29d0c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e108b738-da79-4bfe-8d92-e32379d5fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "with open('data.txt', 'r') as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # 只保留字母和空格\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "words = preprocess(text)\n",
    "vocab = sorted(set(words))\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "n_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3c8d15-8b44-4c0e-93ab-cfcb644ee195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'again', 'ago', 'all', 'along', 'and', 'as', 'away', 'back', 'before']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4321dd3f-6641-436e-868d-804aec610d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'again': 1,\n",
       " 'ago': 2,\n",
       " 'all': 3,\n",
       " 'along': 4,\n",
       " 'and': 5,\n",
       " 'as': 6,\n",
       " 'away': 7,\n",
       " 'back': 8,\n",
       " 'before': 9,\n",
       " 'best': 10,\n",
       " 'breaking': 11,\n",
       " 'but': 12,\n",
       " 'by': 13,\n",
       " 'can': 14,\n",
       " 'changed': 15,\n",
       " 'clearly': 16,\n",
       " 'come': 17,\n",
       " 'cry': 18,\n",
       " 'do': 19,\n",
       " 'each': 20,\n",
       " 'even': 21,\n",
       " 'every': 22,\n",
       " 'favorite': 23,\n",
       " 'fine': 24,\n",
       " 'for': 25,\n",
       " 'friend': 26,\n",
       " 'get': 27,\n",
       " 'gone': 28,\n",
       " 'good': 29,\n",
       " 'had': 30,\n",
       " 'happy': 31,\n",
       " 'has': 32,\n",
       " 'heart': 33,\n",
       " 'her': 34,\n",
       " 'hes': 35,\n",
       " 'how': 36,\n",
       " 'i': 37,\n",
       " 'id': 38,\n",
       " 'in': 39,\n",
       " 'it': 40,\n",
       " 'its': 41,\n",
       " 'just': 42,\n",
       " 'lang': 43,\n",
       " 'like': 44,\n",
       " 'listen': 45,\n",
       " 'long': 46,\n",
       " 'looking': 47,\n",
       " 'lost': 48,\n",
       " 'love': 49,\n",
       " 'made': 50,\n",
       " 'make': 51,\n",
       " 'makes': 52,\n",
       " 'me': 53,\n",
       " 'melodies': 54,\n",
       " 'melt': 55,\n",
       " 'memories': 56,\n",
       " 'memorize': 57,\n",
       " 'more': 58,\n",
       " 'much': 59,\n",
       " 'my': 60,\n",
       " 'not': 61,\n",
       " 'of': 62,\n",
       " 'old': 63,\n",
       " 'on': 64,\n",
       " 'once': 65,\n",
       " 'part': 66,\n",
       " 'played': 67,\n",
       " 'radio': 68,\n",
       " 'rather': 69,\n",
       " 'really': 70,\n",
       " 'sad': 71,\n",
       " 'seem': 72,\n",
       " 'shalalala': 73,\n",
       " 'shines': 74,\n",
       " 'shingalingaling': 75,\n",
       " 'shoobie': 76,\n",
       " 'sing': 77,\n",
       " 'smile': 78,\n",
       " 'so': 79,\n",
       " 'some': 80,\n",
       " 'songs': 81,\n",
       " 'sound': 82,\n",
       " 'starting': 83,\n",
       " 'still': 84,\n",
       " 'such': 85,\n",
       " 'that': 86,\n",
       " 'the': 87,\n",
       " 'them': 88,\n",
       " 'they': 89,\n",
       " 'theyd': 90,\n",
       " 'theyre': 91,\n",
       " 'those': 92,\n",
       " 'times': 93,\n",
       " 'to': 94,\n",
       " 'today': 95,\n",
       " 'waiting': 96,\n",
       " 'was': 97,\n",
       " 'well': 98,\n",
       " 'were': 99,\n",
       " 'when': 100,\n",
       " 'where': 101,\n",
       " 'wondered': 102,\n",
       " 'word': 103,\n",
       " 'would': 104,\n",
       " 'wowo': 105,\n",
       " 'years': 106,\n",
       " 'yesterday': 107,\n",
       " 'young': 108}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b384dab8-4854-4eb6-be35-1a95b40b8ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a',\n",
       " 1: 'again',\n",
       " 2: 'ago',\n",
       " 3: 'all',\n",
       " 4: 'along',\n",
       " 5: 'and',\n",
       " 6: 'as',\n",
       " 7: 'away',\n",
       " 8: 'back',\n",
       " 9: 'before',\n",
       " 10: 'best',\n",
       " 11: 'breaking',\n",
       " 12: 'but',\n",
       " 13: 'by',\n",
       " 14: 'can',\n",
       " 15: 'changed',\n",
       " 16: 'clearly',\n",
       " 17: 'come',\n",
       " 18: 'cry',\n",
       " 19: 'do',\n",
       " 20: 'each',\n",
       " 21: 'even',\n",
       " 22: 'every',\n",
       " 23: 'favorite',\n",
       " 24: 'fine',\n",
       " 25: 'for',\n",
       " 26: 'friend',\n",
       " 27: 'get',\n",
       " 28: 'gone',\n",
       " 29: 'good',\n",
       " 30: 'had',\n",
       " 31: 'happy',\n",
       " 32: 'has',\n",
       " 33: 'heart',\n",
       " 34: 'her',\n",
       " 35: 'hes',\n",
       " 36: 'how',\n",
       " 37: 'i',\n",
       " 38: 'id',\n",
       " 39: 'in',\n",
       " 40: 'it',\n",
       " 41: 'its',\n",
       " 42: 'just',\n",
       " 43: 'lang',\n",
       " 44: 'like',\n",
       " 45: 'listen',\n",
       " 46: 'long',\n",
       " 47: 'looking',\n",
       " 48: 'lost',\n",
       " 49: 'love',\n",
       " 50: 'made',\n",
       " 51: 'make',\n",
       " 52: 'makes',\n",
       " 53: 'me',\n",
       " 54: 'melodies',\n",
       " 55: 'melt',\n",
       " 56: 'memories',\n",
       " 57: 'memorize',\n",
       " 58: 'more',\n",
       " 59: 'much',\n",
       " 60: 'my',\n",
       " 61: 'not',\n",
       " 62: 'of',\n",
       " 63: 'old',\n",
       " 64: 'on',\n",
       " 65: 'once',\n",
       " 66: 'part',\n",
       " 67: 'played',\n",
       " 68: 'radio',\n",
       " 69: 'rather',\n",
       " 70: 'really',\n",
       " 71: 'sad',\n",
       " 72: 'seem',\n",
       " 73: 'shalalala',\n",
       " 74: 'shines',\n",
       " 75: 'shingalingaling',\n",
       " 76: 'shoobie',\n",
       " 77: 'sing',\n",
       " 78: 'smile',\n",
       " 79: 'so',\n",
       " 80: 'some',\n",
       " 81: 'songs',\n",
       " 82: 'sound',\n",
       " 83: 'starting',\n",
       " 84: 'still',\n",
       " 85: 'such',\n",
       " 86: 'that',\n",
       " 87: 'the',\n",
       " 88: 'them',\n",
       " 89: 'they',\n",
       " 90: 'theyd',\n",
       " 91: 'theyre',\n",
       " 92: 'those',\n",
       " 93: 'times',\n",
       " 94: 'to',\n",
       " 95: 'today',\n",
       " 96: 'waiting',\n",
       " 97: 'was',\n",
       " 98: 'well',\n",
       " 99: 'were',\n",
       " 100: 'when',\n",
       " 101: 'where',\n",
       " 102: 'wondered',\n",
       " 103: 'word',\n",
       " 104: 'would',\n",
       " 105: 'wowo',\n",
       " 106: 'years',\n",
       " 107: 'yesterday',\n",
       " 108: 'young'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90143dbb-88f8-4276-9112-149836abcda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建训练数据\n",
    "def create_sequences(words, seq_length):\n",
    "    sequences = []\n",
    "    for i in range(len(words) - seq_length):\n",
    "        seq = words[i:i + seq_length]\n",
    "        label = words[i + seq_length]\n",
    "        sequences.append((seq, label))\n",
    "    return sequences\n",
    "\n",
    "seq_length = 5\n",
    "sequences = create_sequences(words, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6480f39b-9455-461e-bd3e-d669d8142cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['yesterday', 'once', 'more', 'when', 'i'], 'was'),\n",
       " (['once', 'more', 'when', 'i', 'was'], 'young'),\n",
       " (['more', 'when', 'i', 'was', 'young'], 'id'),\n",
       " (['when', 'i', 'was', 'young', 'id'], 'listen'),\n",
       " (['i', 'was', 'young', 'id', 'listen'], 'to')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]  #5个词一组,label为下一个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1955a8a-94a5-47fd-9a0a-cf847d1d53df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(RNNLanguageModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        out, _ = self.rnn(x)  #输出：out:每个时间步的预测值，_: 隐藏状态向量h\n",
    "        out = self.fc(out[:, -1, :])  # 只取最后一个时间步的输出\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217475bb-3ef6-43c2-a871-9a73a5ca7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 数据集和数据加载器\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, word_to_ix):\n",
    "        self.sequences = sequences\n",
    "        self.word_to_ix = word_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq, label = self.sequences[idx]\n",
    "        seq_tensor = torch.tensor([self.word_to_ix[word] for word in seq], dtype=torch.long)\n",
    "        label_tensor = torch.tensor(self.word_to_ix[label], dtype=torch.long)\n",
    "        return seq_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd22366-91fa-4164-8be4-1a8d54506d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([107,  65,  58, 100,  37]), tensor(97)),\n",
       " (tensor([ 65,  58, 100,  37,  97]), tensor(108)),\n",
       " (tensor([ 58, 100,  37,  97, 108]), tensor(38)),\n",
       " (tensor([100,  37,  97, 108,  38]), tensor(45)),\n",
       " (tensor([ 37,  97, 108,  38,  45]), tensor(94)),\n",
       " (tensor([ 97, 108,  38,  45,  94]), tensor(87)),\n",
       " (tensor([108,  38,  45,  94,  87]), tensor(68)),\n",
       " (tensor([38, 45, 94, 87, 68]), tensor(96)),\n",
       " (tensor([45, 94, 87, 68, 96]), tensor(25)),\n",
       " (tensor([94, 87, 68, 96, 25]), tensor(60))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TextDataset(sequences, word_to_ix)   #样本索引化\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)  #batch_size划分\n",
    "list(dataset)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8704836b-6970-4ea1-96e4-a687006ffaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.8607\n",
      "Epoch [20/100], Loss: 0.3517\n",
      "Epoch [30/100], Loss: 0.0936\n",
      "Epoch [40/100], Loss: 0.0725\n",
      "Epoch [50/100], Loss: 0.0393\n",
      "Epoch [60/100], Loss: 0.1511\n",
      "Epoch [70/100], Loss: 0.1534\n",
      "Epoch [80/100], Loss: 0.0179\n",
      "Epoch [90/100], Loss: 0.0127\n",
      "Epoch [100/100], Loss: 0.1553\n"
     ]
    }
   ],
   "source": [
    "# 模型、损失函数和优化器\n",
    "model = RNNLanguageModel(n_vocab, embedding_dim, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练过程\n",
    "for epoch in range(num_epochs):\n",
    "    for seq_tensor, label_tensor in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(seq_tensor)\n",
    "        loss = criterion(output, label_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d177c7-f8ca-4d2f-98a3-2bc921c066f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was in years gone by and the good times that\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(model, start_word, length):\n",
    "    model.eval()\n",
    "    words = [start_word]\n",
    "    input_seq = torch.tensor([[word_to_ix[start_word]]], dtype=torch.long) #起始词索引化\n",
    "\n",
    "    for _ in range(length):  #指定长度的句子\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq)\n",
    "            _, predicted = torch.max(output, dim=1) #第二个维度上的最大值及其索引\n",
    "            next_word = ix_to_word[predicted.item()]  #索引对应的单词\n",
    "            words.append(next_word) #串入words\n",
    "\n",
    "            # 更新输入序列\n",
    "            input_seq = torch.cat([input_seq, predicted.view(1, 1)], dim=1)\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# 生成句子示例\n",
    "start_word = 'it'  # 你可以选择任何在词汇表中的单词,已全部小写\n",
    "sentence_length = 10\n",
    "generated_sentence = generate_sentence(model, start_word, sentence_length)\n",
    "print(generated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699222a-b6d6-431d-bd7f-442f0ed504bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
